<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>org:jrbeverly on jrbeverly</title><link>/tags/orgjrbeverly/</link><description>Recent content in org:jrbeverly on jrbeverly</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Thu, 19 May 2022 00:58:15 +0000</lastBuildDate><atom:link href="/tags/orgjrbeverly/index.xml" rel="self" type="application/rss+xml"/><item><title>swagger-golang-bazelgen-exp</title><link>/2022/05/jrbeverly-swagger-golang-bazelgen-exp/</link><pubDate>Thu, 19 May 2022 00:58:15 +0000</pubDate><guid>/2022/05/jrbeverly-swagger-golang-bazelgen-exp/</guid><description>Golang &amp;amp; OpenAPI Spec Fiddling with an idea of generating models from the OpenAPI spec for YAML.
Notes Bazel model works, but would want to formalize as a proper build system Model of pkg/apis/... is a good direction, version selecting will need to be a thing though What about YAML Support? Is swagger the expected way forward for this kind of thing? Should the generation of files be done as a bazel run or a bazel build?</description></item><item><title>graphql-golang-note-check</title><link>/2022/05/jrbeverly-graphql-golang-note-check/</link><pubDate>Wed, 18 May 2022 23:21:25 +0000</pubDate><guid>/2022/05/jrbeverly-graphql-golang-note-check/</guid><description>Fiddling with gqlgen Experimenting a bit with gqlgen for generating GraphQL code from spec.
Notes Would prefer to move gqlgen.yml and schema.graphql into a spec/ directory (or other areas) Installation method with tools.go - not sure about this, static binary is preferrable for my usages Generated models are pretty solid, similar to swagger Resolvers is nice, but what about partial updates? I&amp;rsquo;m not entirely sold on this pattern. Feel like I&amp;rsquo;d prefer more flexibility with how the models and various components are defined.</description></item><item><title>react-xstate-machines</title><link>/2022/05/jrbeverly-react-xstate-machines/</link><pubDate>Wed, 18 May 2022 23:14:27 +0000</pubDate><guid>/2022/05/jrbeverly-react-xstate-machines/</guid><description>State Machine for Confirmation Dialog Running through the workshop example of Build A Confirmation Modal in React with State Machines
Notes In principal, like the idea of representation this kinds of logic &amp;ldquo;Flows&amp;rdquo; Usage of strings for state is less than ideal, almost would want it to be objects Pattern of constructing a &amp;ldquo;flow&amp;rdquo; then making use of the &amp;ldquo;flow&amp;rdquo; Potential opportunities with systems like codegen Possible ideas for test evaluation with the states Not sure about this library, needs opportunities for isolation Feels like it doesn&amp;rsquo;t fit with the View -&amp;gt; ViewModel -&amp;gt; Model concept I was thinking of for State Machines The &amp;lsquo;dispatcher&amp;rsquo; works similar to what a wrapper over &amp;ldquo;Modal&amp;rdquo; would have, what benefits does it bring?</description></item><item><title>exp-pulumi-lambda</title><link>/2022/05/jrbeverly-exp-pulumi-lambda/</link><pubDate>Wed, 18 May 2022 00:40:54 +0000</pubDate><guid>/2022/05/jrbeverly-exp-pulumi-lambda/</guid><description>Experimenting with Pulumi Experimenting with the pulumi examples from https://github.com/pulumi/examples, and the options to have
Notes Enabling Bazel wtih this model encountered some pain points Pulumi is capable of performing operations like Docker Build / Referencing lambda binaries The change source pattern (git.dirty, git.author, etc) for volatile status is a nice pattern Building of artifacts should not be the responsibility of the deployment model Pulumi takes over the context element of deployments, and use that for deployments Pulumi has some nice elements too it with respect to be able to use code to create the deployment, as well as a good web/console interface.</description></item><item><title>golang-gin-gitpod</title><link>/2022/05/jrbeverly-golang-gin-gitpod/</link><pubDate>Wed, 18 May 2022 00:23:29 +0000</pubDate><guid>/2022/05/jrbeverly-golang-gin-gitpod/</guid><description>Golang Gin &amp;amp; Gitpod Fiddling with the Dev experience of Golang gin within Gitpod
Based on gitpod-io/go-gin-app
Notes Prefer the pattern of combining this with cobra Server rendered HTML is pretty straightforward Returning simple JSON pretty straightforward Can be combined with GRPC + Proto What about swagger for generating the modules? Considerations about how to organize the elements (cli, server, routes, models, database, etc) What about logging for this? Gitpod has occassionally issues with the import of gin References for things like templates/ at the top level is nice Log while running is excellent Overall positive.</description></item><item><title>reminders-miragejs</title><link>/2022/05/jrbeverly-reminders-miragejs/</link><pubDate>Wed, 18 May 2022 00:07:08 +0000</pubDate><guid>/2022/05/jrbeverly-reminders-miragejs/</guid><description>MirageJS Tutorial Running through the (MirageJS Tutorial)[https://github.com/miragejs/tutorial] case
Notes If generated from a schema, the system is essentially Backend (proper) Backend Mock (in-memory) Backend JS Client (proper) Backend JS Client Mock (in-memory - integrated with MirageJS) How could this be integrated with code generation from a specification? Does this assist with local development? Test scenarios in an pseudo-E2E case?</description></item><item><title>manim-exp-video-generation</title><link>/2022/05/jrbeverly-manim-exp-video-generation/</link><pubDate>Tue, 17 May 2022 02:10:19 +0000</pubDate><guid>/2022/05/jrbeverly-manim-exp-video-generation/</guid><description>MAnim Experimentation with Video Generation Experimenting with the MAnim library for generating video animations.
Notes Solid library that works really well at what it does Scenes feel very &amp;ldquo;on-track&amp;rdquo; in that it is a sequence of steps one followed by the next Python allows for re-use to create common elements like an isometric file Works great for scenes where the emphasis is on the core &amp;ldquo;shapes&amp;rdquo; and animation Don&amp;rsquo;t think this fits with the use-case I&amp;rsquo;m after.</description></item><item><title>react-wasm-babel</title><link>/2022/05/jrbeverly-react-wasm-babel/</link><pubDate>Tue, 17 May 2022 02:05:18 +0000</pubDate><guid>/2022/05/jrbeverly-react-wasm-babel/</guid><description>React Webpack with Rust WebAssembly Fiddling around with an opinionated example for Webpack builds with WebAssembly.
Source code for fractal is based on https://dev.to/brightdevs/using-webassembly-with-react-1led, and the repository templated by https://github.com/Fallenstedt/wasm-react-webpack-template.
Notes WASM Build works pretty well with rust Rust is a solid option for getting webassembly integrated Golang was considered, but previous experiments weren&amp;rsquo;t as desired Makefile as an entrypoint is preferrable than using yarn ... Embedding the generated packages within the front (e.</description></item><item><title>vuln-disclosure-policy</title><link>/2022/05/jrbeverly-vuln-disclosure-policy/</link><pubDate>Fri, 13 May 2022 03:25:29 +0000</pubDate><guid>/2022/05/jrbeverly-vuln-disclosure-policy/</guid><description>Vulnerability Disclosure Policy from Dioterms Exploring leveraging dioterms and policymaker for creating vulnerability disclore policies for a website.
Notes DNS is related for the deployment of the website (_security) Entry within the /.well-known/ root of the domain (example.com/.well-known/security.txt) Security entry for the domain (example.com/security) If the application is located within example.com/app/... (e.g. index.html), then the top level domain elements can be &amp;ldquo;procedural&amp;rdquo; Construct the webpage into a bundle (website.wbn), publish it to the &amp;ldquo;deployer&amp;rdquo;, which can then handle the top level elements References can still exist within the app (/security, /.</description></item><item><title>bazel-terraform-conftest-experiments</title><link>/2022/05/jrbeverly-bazel-terraform-conftest-experiments/</link><pubDate>Wed, 11 May 2022 02:21:49 +0000</pubDate><guid>/2022/05/jrbeverly-bazel-terraform-conftest-experiments/</guid><description>Experimenting with ConfTest, Terraform &amp;amp; Bazel Experimenting with using Bazel to handle the build &amp;amp; execution of Terraform files, while providing means of writing tests against the terraform with conftest. Fiddling with the idea of having local tests against the configuration, as well as tests against the terraform plan.
The intention is that Bazel would be responsible for constructing Terraform deployable tarballs, which contains all resolved modules &amp;amp; providers. These would be executed to perform apply, plan and other commands.</description></item><item><title>asdf</title><link>/2022/05/jrbeverly-asdf/</link><pubDate>Tue, 10 May 2022 22:33:19 +0000</pubDate><guid>/2022/05/jrbeverly-asdf/</guid><description>asdf Manage multiple runtime versions with a single CLI tool, extendable via plugins - docs at asdf-vm.com
asdf is a CLI tool that can manage multiple language runtime versions on a per-project basis. It is like gvm, nvm, rbenv &amp;amp; pyenv (and more) all in one! Simply install your language&amp;rsquo;s plugin!
Why use asdf? single CLI for multiple languages consistent commands to manage all your languages single global config keeping defaults in one place single .</description></item><item><title>julia-with-jupyter-notebook</title><link>/2022/04/jrbeverly-julia-with-jupyter-notebook/</link><pubDate>Thu, 07 Apr 2022 03:14:33 +0000</pubDate><guid>/2022/04/jrbeverly-julia-with-jupyter-notebook/</guid><description>Julia Jupyter Notebook Experiments with working with Julia &amp;amp; Jupyter Notebooks.
Notes Installation of Jupyter, Conda + Julia (+ packages) onto a gitpod image Makefile for common actions working with the notebooks Validating some basic cases working with Julia for generating plots &amp;amp; other bits for the visualization</description></item><item><title>gitpod-jupyter-notebook</title><link>/2022/03/jrbeverly-gitpod-jupyter-notebook/</link><pubDate>Thu, 17 Mar 2022 23:41:20 +0000</pubDate><guid>/2022/03/jrbeverly-gitpod-jupyter-notebook/</guid><description>GitPod Jupyter Notebook Validating working with Jupyter notebooks in a GitPod environments
Notes Support for preview or open in browser mode Initial provisioning of the image takes a bit, pre-baked likely would help in this area Jupyter lab is another option Makefile is a good option for acting as an entrypoint for common commands Outstanding questions still exist for multi-notebook repositories like the learning repo</description></item><item><title>pushgateway-compose-setup</title><link>/2022/03/jrbeverly-pushgateway-compose-setup/</link><pubDate>Tue, 15 Mar 2022 22:33:21 +0000</pubDate><guid>/2022/03/jrbeverly-pushgateway-compose-setup/</guid><description>Pushgateway Compose Setup Simple code setup for spinning up Pushgateway, Prometheus &amp;amp; Grafana for validating lifecycle pushgateway metrrics.
Notes Metrics published to pushgateway are collected by Prometheus Prometheus is enabled in Grafana for queries Grafana datasources &amp;amp; dashboards are configured from the provisioning directory The script publish.sh can be used to publish the metrics into the system Dashboards in grafana/dashboards can be configured with other tools for construction Dashboards could be standardized, then shared into other sources Tools can be configured for publishing in these scenarios</description></item><item><title>aws-exp-organizations-policy</title><link>/2022/03/jrbeverly-aws-exp-organizations-policy/</link><pubDate>Sun, 06 Mar 2022 21:32:19 +0000</pubDate><guid>/2022/03/jrbeverly-aws-exp-organizations-policy/</guid><description>AWS Organization Structure Experiments - Mirrored Organizations Experiments with AWS Organization structure and potential SCP policies.
Notes The entire organization unit hierarchy shouldn&amp;rsquo;t be a single entity for mirroring. Makes it difficult to evaluate in &amp;ldquo;isolation&amp;rdquo; Entire organization mirrors can work with the SCPs, but internal permissions (e.g. S3 Bucket) still might have issues Organizations should include a uniqueness component to allow for constructing a new version (&amp;amp; prototyping) SCPs seem like they would benefit in cases where there is a sort of &amp;ldquo;State machine&amp;rdquo; in the SCP State machine examples are &amp;ldquo;During provisioning of account, need to create IAM Users, but from then on no users should be created&amp;rdquo; Account boundaries for services as a way of strictly locking things makes it easier to have DenyKMS and other such policies Region denies only apply after provisioning, as we need to purge the &amp;ldquo;default VPCs&amp;rdquo; created when an AWS Account is created (+ any other &amp;ldquo;default&amp;rdquo; resources) AWS Password Policy / AWS IAM Account Name / Etc are all good examples of something that should only need to be provisioned &amp;ldquo;once&amp;rdquo; SCPs give a potential idea for the concept of &amp;ldquo;Immutable AWS Account Infrastructure&amp;rdquo;, that require you to create a new AWS Account (+ migrate resources) rather than edit them Sandbox/Staging organizations can contain the developer workloads that are for sandbox/development Developer workloads should be contained within accoounts that can be created/decommissioned on a release schedule (see ubuntu - Bionic Beaver, Focal Fossa, Xenial Xerus) More investigation is needed into this idea, as the exact &amp;ldquo;concern&amp;rdquo; that this kind of structure &amp;amp; SCP policy layout will handle is kind of vague.</description></item><item><title>github-pullthrough-mirror</title><link>/2022/03/jrbeverly-github-pullthrough-mirror/</link><pubDate>Fri, 04 Mar 2022 04:32:17 +0000</pubDate><guid>/2022/03/jrbeverly-github-pullthrough-mirror/</guid><description>Release Mirror for GitHub Releases Lightweight experiment for mirroring GitHub releases into a file store system like Minio or AWS S3.
Getting Started packages/ Contains the tool definition files for each of the mirror repositories (tool.ini), and the computed checksums for the downloaded files. In an actual use case it would be better to store the checksums externally from this repository, allowing this one to act purely as an executor, and the other repository acting as a &amp;ldquo;record&amp;rdquo; of the known-good commit SHAs (as well as .</description></item><item><title>github-config-in-code</title><link>/2022/03/jrbeverly-github-config-in-code/</link><pubDate>Wed, 02 Mar 2022 02:14:31 +0000</pubDate><guid>/2022/03/jrbeverly-github-config-in-code/</guid><description>GitHub Configuration in Code Fiddling with the configuration options available for GitHub, while encoding the properties in the .github directory.
Getting Started This repository
The concept is to create an almost &amp;ldquo;self-contained&amp;rdquo; repository, that includes within hidden directories like .github/.aws/.azure/.gcp/etc that represent almost &amp;ldquo;interfaces&amp;rdquo; between the repository and external services that would act on it. This way rather than having the repository rely on assumptions about how it is configured, it is instead providing all the baseline elements for any supporting infrastructure (e.</description></item><item><title>github-app-for-code-change</title><link>/2022/02/jrbeverly-github-app-for-code-change/</link><pubDate>Wed, 23 Feb 2022 00:11:59 +0000</pubDate><guid>/2022/02/jrbeverly-github-app-for-code-change/</guid><description>GitHub App for Generated Commits Running through a bunch of things to be done with this
Notes Is it possible to push empty commits, which would need to be handled Commits should be crafted first, then attempts being made to apply the change Would need to have better visibility into the &amp;ldquo;crafted&amp;rdquo; files that will be committed Does this really require a GitHub Application? Feels like this could be decoupled Need to ensure that requests with the API go through the proper retry processes Need to ensure that the configuration is split from auth, so its easier to rotate the auth without fiddling with the config Should the app really be responsible for the work-component of crafting the change?</description></item><item><title>gpg-artifact-sign-exp</title><link>/2022/01/jrbeverly-gpg-artifact-sign-exp/</link><pubDate>Thu, 27 Jan 2022 02:07:13 +0000</pubDate><guid>/2022/01/jrbeverly-gpg-artifact-sign-exp/</guid><description>GPG Artifact Sign Experiment Minor experiment with a shell script for signing artifacts that would be generated from a build process.
Notes Build tooling can support multiple checksum algorithms (sha256/sha1/md5/sha512/etc) Docker Container Trust (DCT) didn&amp;rsquo;t fit with the usecase/portability desired GPG is the standard way for doing this (can this be packaged into something more portable?) Design should aim to be agnostic of GitHub Releases or any other platform Build tooling likely doesn&amp;rsquo;t need to understand the concept of &amp;ldquo;signing&amp;rdquo; (or should it?</description></item><item><title>bevy-rustlang-example-window</title><link>/2022/01/jrbeverly-bevy-rustlang-example-window/</link><pubDate>Thu, 27 Jan 2022 02:02:45 +0000</pubDate><guid>/2022/01/jrbeverly-bevy-rustlang-example-window/</guid><description>Rusy Bevy Baseline Fiddling with one of the Bevy examples for provisioning a window with Bevy.
Notes Initialize setup required installation of libraries like: libasound2-dev libwebkit2gtk-4.0 libudev-dev mingw-w64 Cross-compilation works, but associated GitHub Issues seemed conflicting Earlier version of bevy had issue with missing audio driver (devcontainer) failing the build Don&amp;rsquo;t think will continue with this for now, maybe investigate later.
Components for the chess board sourced from https://caballerocoll.</description></item><item><title>exp-webassembly-golang-bazel</title><link>/2022/01/jrbeverly-exp-webassembly-golang-bazel/</link><pubDate>Thu, 27 Jan 2022 00:52:56 +0000</pubDate><guid>/2022/01/jrbeverly-exp-webassembly-golang-bazel/</guid><description>Experiment - WebAssembly Golang + Bazel Experimenting with some issues encountering with WebAssembly, Golang &amp;amp; Bazel
Notes Confirmed issue with syscall/js in the basecase with using goos and goarch (toolchains passed as orgs better option?) Using a genrule sufficient to workaround the case Base case with a simple calculator, using just base HTML js.Value conversions, framework wrapper to exist to handle the interop? Directory layout of cmd/ and app feels a bit off, but does help keep the bits separate</description></item><item><title>packer-overwrite-motd</title><link>/2022/01/jrbeverly-packer-overwrite-motd/</link><pubDate>Thu, 27 Jan 2022 00:27:16 +0000</pubDate><guid>/2022/01/jrbeverly-packer-overwrite-motd/</guid><description>Packer Overwrite MOTD Overwriting the MOTD of pre-baked AMIs using Packer
Notes Message files are located in /etc/update-motd.d/ Existing ones can be purged and replaced with a fixed one Likely want to keep the status components (source from existing, overwrite) Scripts need to be executable, and include shebang Current packer requires AWS for EC2 create/snapshot, can we avoid? This works well for setting up a baseline for the AMIs.</description></item><item><title>cobra-cmd-with-docs</title><link>/2022/01/jrbeverly-cobra-cmd-with-docs/</link><pubDate>Wed, 26 Jan 2022 04:11:54 +0000</pubDate><guid>/2022/01/jrbeverly-cobra-cmd-with-docs/</guid><description>CobraCMD with GenMarkdownTree Experiment with the GenMarkdownTree method available with cobrago.
Actions The command line utility can be executed by running:
bazel run //cmd/cobradocs version The markdown tree for the docs can be generated by running:
bazel run //docs/cobradocs -- --dir $PWD Notes Markdown or YAML generated from the docs works fairly nice Better fit would be YAML, then providing it to a markdown templator (or alternative tools) Feels like having an OpenAPI spec for the CLI would make this process easier (build docs from the OpenAPI spec) Need to have a reference to the command object for the CLI Files are written into a directory, or dumped to a buffer &amp;amp; stdout Can be good for getting some docs out, but is this the ideal direction?</description></item><item><title>xterm-for-cmd-as-site</title><link>/2022/01/jrbeverly-xterm-for-cmd-as-site/</link><pubDate>Wed, 26 Jan 2022 04:07:04 +0000</pubDate><guid>/2022/01/jrbeverly-xterm-for-cmd-as-site/</guid><description>XTerm for Terminal as Browser Experimenting with the idea of a minimum environment for running terminal applications in browser. In essence, allowing a user to navigate to example.com/terminal to view a terminal version of the sites API. With the appropriate token &amp;amp; other bits provided from the browser session tokens.
Notes WebAssembly for Golang can be used in combination with this Browser token can be used to authenticate with the service, allowing for commands to exec against it Using something like the cobra yaml export (or deriving actions from OpenAPI-like spec), the JS interface can be generated Validation would be performed within the cmd, although a common &amp;lsquo;OpenAPI-like&amp;rsquo; spec would help reduce the complexity on this front (have better interacted with UIs) Leveraging other wrapper frameworks for xTerm.</description></item><item><title>aws-assumerole-with-cert</title><link>/2022/01/jrbeverly-aws-assumerole-with-cert/</link><pubDate>Wed, 26 Jan 2022 03:27:23 +0000</pubDate><guid>/2022/01/jrbeverly-aws-assumerole-with-cert/</guid><description>AWS AssumeRole with Certificate for CI Exploring the concept of using AWS IoT Certificates for authenticating with AWS.
This came up while working with minio, which supports authentication with certificates:
MinIO provides a custom STS API that allows authentication with client X.509 / TLS certificates.
Getting Started The commands boostrap.sh and cert.sh are provided for working with the IoT devices. Bootstrap is responsible for provisioning the certificate, IoT resources, and the permissionless IAM role.</description></item><item><title>cloudfront-cognito-private-auth</title><link>/2022/01/jrbeverly-cloudfront-cognito-private-auth/</link><pubDate>Wed, 26 Jan 2022 02:50:02 +0000</pubDate><guid>/2022/01/jrbeverly-cloudfront-cognito-private-auth/</guid><description>AWSS3 &amp;amp; AWS Cognito Fiddling with AWS S3 Websites leveraging AWS Cognito for authentication
Terraform is based on the tutorial https://transcend.io/blog/restrict-access-to-internal-websites-with-beyondcorp/ and the public repository: https://github.com/transcend-io/beyondcorp-cloudfront
Notes This approach isn&amp;rsquo;t really something I think is great The lack of ease configuration for Lambdas, and the need to either embed configuration in the lambda zip, or through AWS SSM is not ideal Either a single monolith terraform module, or split between multiple.</description></item><item><title>rules_docker</title><link>/2022/01/jrbeverly-rules_docker/</link><pubDate>Wed, 12 Jan 2022 01:24:06 +0000</pubDate><guid>/2022/01/jrbeverly-rules_docker/</guid><description>Bazel Container Image Rules Bazel CI Generated API documentation is in the docs folder, or you can browse it online at https://docs.aspect.dev/rules_docker
Basic Rules container_image (example) container_bundle (example) container_import container_load container_pull (example) container_push (example) These rules used to be docker_build, docker_push, etc. and the aliases for these (mostly) legacy names still exist largely for backwards-compatibility. We also have early-stage oci_image, oci_push, etc.</description></item><item><title>dapper-with-entity-model</title><link>/2021/10/jrbeverly-dapper-with-entity-model/</link><pubDate>Sat, 23 Oct 2021 14:43:17 +0000</pubDate><guid>/2021/10/jrbeverly-dapper-with-entity-model/</guid><description>EntityModel Dapper Experiment Case Exported case of experimenting with using Postgres Functions, Dapper &amp;amp; Entity.Model.
Notes Experimenting a bit more with the entity model of splitting out the &amp;ldquo;database&amp;rdquo; components (e.g. ID) from the model objects, with an aim towards designing a strict interface for working with the database, that could be generated from a baseline specification. This would allow for things like ReadOnly entities, better field filtering &amp;amp; potential for &amp;ldquo;programmatic&amp;rdquo; improvements to how the database handles searches.</description></item><item><title>cue-for-schema-gen</title><link>/2021/10/jrbeverly-cue-for-schema-gen/</link><pubDate>Sat, 23 Oct 2021 00:46:21 +0000</pubDate><guid>/2021/10/jrbeverly-cue-for-schema-gen/</guid><description>Cuelang with SchemaGen Experimenting with using Cuelang for the purposes of representing a schema, then generating associated files from the original source of truth
Notes Schema validation is nice, the base case is straightforward Combining data with this allows for connecting enum/datasets What about stubbing of datasets (e.g. restrict this to &amp;lsquo;Dataset&amp;rsquo; that isn&amp;rsquo;t locally defined?) Text templating isn&amp;rsquo;t really what I want to do with this kind of tool Seems like I need to write more &amp;ldquo;representation/composition&amp;rdquo; than I originally hoped Doesn&amp;rsquo;t seem to support the kind of &amp;ldquo;intentions&amp;rdquo; workflow I was hoping for This isn&amp;rsquo;t handling the case I&amp;rsquo;m interested in with schema validation &amp;amp; generation.</description></item><item><title>bazel-bash-packaged</title><link>/2021/10/jrbeverly-bazel-bash-packaged/</link><pubDate>Tue, 05 Oct 2021 23:00:41 +0000</pubDate><guid>/2021/10/jrbeverly-bazel-bash-packaged/</guid><description>Bazel Bash Packaged Experimenting with using Bazel &amp;amp; Bats in container images for writing up tests for shell scripts.
Notes Sometimes while developing things it can be useful to have a small shell script that performs a simple action or operation, that in the short-term makes sense as a shell script. In this case, it can be useful to add some simple tests to ensure that:
The script is runnable Simple transformations work as expected Any environment variable or file references work as intended This isn&amp;rsquo;t intended for cases where a shell script is increasing in complexity, but rather where it acts as &amp;lsquo;Glue&amp;rsquo; responsible for filling in gaps that might exist in a system.</description></item><item><title>jcompiler</title><link>/2021/10/jrbeverly-jcompiler/</link><pubDate>Mon, 04 Oct 2021 23:31:06 +0000</pubDate><guid>/2021/10/jrbeverly-jcompiler/</guid><description>JCompiler Summary A Joos programming language compiler, written in Java.
Getting Started The project is currently not maintained or kept in runnable order. You may be able to open the project in Eclipse, but at this time the code is only here as readonly.
Notes The application was written as part of the UWaterloo CS444 Compiler Course.
Group Members:
seanmk sxyuan Acknowledgements The project icon is retrieved from the Noun Project.</description></item><item><title>bazel-toolchain-from-s3</title><link>/2021/09/jrbeverly-bazel-toolchain-from-s3/</link><pubDate>Sun, 26 Sep 2021 23:53:42 +0000</pubDate><guid>/2021/09/jrbeverly-bazel-toolchain-from-s3/</guid><description>bazel-toolchain-from-s3 Experimenting with setting up Bazek toolchains, when the tools are mirrored into an AWS S3 bucket.
This builds off previous work done in jrbeverly/bazel-external-toolchain-rule for creating toolchains from files.
Notes Implementation of s3_archive uses that same model as http_archive The repository_rule does not use toolchains like rules, meaning bootstrap rules must be downloaded by repository_ctx Repository rules can convert labels to paths using the repository_ctx.path method To get a fully managed system that doesn&amp;rsquo;t require tools to be installed on the local system, would likely require a bootstrap rule using a tool that is publicly available.</description></item><item><title>bazel-external-toolchain-rules</title><link>/2021/09/jrbeverly-bazel-external-toolchain-rules/</link><pubDate>Sun, 26 Sep 2021 22:20:07 +0000</pubDate><guid>/2021/09/jrbeverly-bazel-external-toolchain-rules/</guid><description>bazel-external-toolchain-rules Experimenting with setting up Bazel toolchains using an externally managed .toolchain file, that is responsible for defining properties such as:
System compatibility Integrity Checks Tool retrieval locations Notes This idea came out of the idea of having Bazel rules that were not aware of how toolchains were defined (or what systems they are compatible with), and instead being entirely based on the lock file (.toolchain) available in the caller environment.</description></item><item><title>bazel-jsonnett-templates</title><link>/2021/09/jrbeverly-bazel-jsonnett-templates/</link><pubDate>Sun, 12 Sep 2021 17:15:18 +0000</pubDate><guid>/2021/09/jrbeverly-bazel-jsonnett-templates/</guid><description>Bazel &amp;amp; Jsonnet Templates Generating files from base configuration files using Jsonnet.
Notes Exploring the idea of leveraging jsonnet with Bazel to create a series of templates sourced from configuration files. The basic principle of this is how to built in-repository the idea of ∀ ∈ Configuration Files { template([inputs]) =&amp;gt; rendered }.
The usage of libsonnet lets the lib/ directory contain all of the models, utilities and other means of representing the data structures.</description></item><item><title>internal-reserved-license-repo</title><link>/2021/09/jrbeverly-internal-reserved-license-repo/</link><pubDate>Sat, 11 Sep 2021 19:18:11 +0000</pubDate><guid>/2021/09/jrbeverly-internal-reserved-license-repo/</guid><description>internal-reserved-license-repo Experimenting with laying out the licensing stamp for a closed/internal source repository
Notes Experimenting with the idea of what license annotations would look like on an internal repository that is not intended for public distribution. This can seem odd, as the source code files of the project should not be distributed, so the only individuals viewing the license should be those with pre-approved access (i.e. contributors/employees).
The intention of this is to explore ideas around having tools &amp;amp; systems be aware of the licensing &amp;ldquo;intentions&amp;rdquo; of the source code.</description></item><item><title>github-actions-dbx-upload</title><link>/2021/08/jrbeverly-github-actions-dbx-upload/</link><pubDate>Sat, 28 Aug 2021 22:26:52 +0000</pubDate><guid>/2021/08/jrbeverly-github-actions-dbx-upload/</guid><description>github-actions-dbx-upload Publishing to Dropbox programmatically from GitHub Actions with the intentions to mirror the model of AWS S3 publishing.
Notes Exploring how one might leverage Dropbox as an artifact storage source, with an authentication model that is similar to AWS. Setting up the initial Dropbox Application to get the tokens for publishing was a bit more involved than useful, and I suspect the process of rotating these tokens might be a pain too.</description></item><item><title>terraform-aws-codepipeline-terraform-runner</title><link>/2021/08/jrbeverly-terraform-aws-codepipeline-terraform-runner/</link><pubDate>Sat, 28 Aug 2021 14:39:46 +0000</pubDate><guid>/2021/08/jrbeverly-terraform-aws-codepipeline-terraform-runner/</guid><description>Terraform AWS CodePipline Terraform Executor Terraform executor leveraging the CodePipeline functionality in AWS, for a fully serverless model of executing terraform in AWS.
Getting Started The primary environment is configured in env/, with a single main file. This provisions the CodePipeline, CodeBuild components, as well as some stub S3 buckets that represent both incoming sources, artifacts. The artifacts bucket is treated as a stand-in for the Terraform state environment variable, but the pipeline itself does not attempt to configure the backend for S3.</description></item><item><title>golang-analyzer-inline-bazel</title><link>/2021/08/jrbeverly-golang-analyzer-inline-bazel/</link><pubDate>Wed, 18 Aug 2021 01:16:50 +0000</pubDate><guid>/2021/08/jrbeverly-golang-analyzer-inline-bazel/</guid><description>Bazel Golang Inline Analyzer Experimenting with having analyzers locally defined to a repository, rather than externally defined.
Notes Requires using go_tool_library instead of go_library due to a dependency change issue (must also use go_tool_library of deps) Baked natively into nogo, so it can be pretty straightforward to test Names of types aren&amp;rsquo;t as simple as package.Type, but instead include other components (using HasSuffix) (What options are there?) Change in &amp;lsquo;internal/cobrago/storage.</description></item><item><title>github-app-golang</title><link>/2021/07/jrbeverly-github-app-golang/</link><pubDate>Fri, 16 Jul 2021 16:57:05 +0000</pubDate><guid>/2021/07/jrbeverly-github-app-golang/</guid><description>GitHub App in Golang Prototyping GitHub App written in Golang with the AWS &amp;amp; GitHub integrations split away, to try and encode the core &amp;lsquo;concepts&amp;rsquo; solely into the lib/ component
Notes Development (&amp;amp; Testing) should support a non-smee way of development How would integration/infrastructure/e2e tests work with this kind of system? Would it make more sense to have an OpenAPI system, with the GitHub integration performing the interface? Is this similar to Hubot, in that having an interface layer/service makes more sense, as it avoids the requirement for direct interface?</description></item><item><title>k3s-at-home-poc</title><link>/2021/07/jrbeverly-k3s-at-home-poc/</link><pubDate>Mon, 12 Jul 2021 20:40:29 +0000</pubDate><guid>/2021/07/jrbeverly-k3s-at-home-poc/</guid><description>K3s In HomeLab Proof of Concept Determining how viable it would to be switch from using docker-compose to using K3s to run my internal homelab environment.
Getting Started The installation process assumes that you have a freshly imaged ubuntu machine, connected to the internal network, and with a minimum of password-based SSH access.
Installing dependencies The tools FluxCD &amp;amp; K3sup can be installed on the host machine using the script setup.</description></item><item><title>gitpod-cobra-golang</title><link>/2021/07/jrbeverly-gitpod-cobra-golang/</link><pubDate>Mon, 12 Jul 2021 19:10:27 +0000</pubDate><guid>/2021/07/jrbeverly-gitpod-cobra-golang/</guid><description>GitPod Golang CLI Leveraging GitPod for prototyping out a golang cli that interfaces with AWS.
Notes The .gitpod.yml file must exist in the root directory Dockerfile(s) for the environment can be specified in its own directory (.gitpod) Commands can be run on start-up, ensuring that the build is working as expected GitHub Permissions required to make changes to GitHub Actions workflows GitHub Permissions required for a series of commit/pull request based actions Workspaces can be provisioned/stopped/cleaned up on-demand Docker works on the provisioned nodes Extensions &amp;amp; Other components are defined by the .</description></item><item><title>rust-lang-checks</title><link>/2021/07/jrbeverly-rust-lang-checks/</link><pubDate>Mon, 12 Jul 2021 15:05:14 +0000</pubDate><guid>/2021/07/jrbeverly-rust-lang-checks/</guid><description>Rust Language Checks Experimenting with aspects of Rustlang for working with database, and immutable data structures.
Notes How might the Entity.Model apply to this? Where we split the id from the data struct? Immutable hashmap appears to need additional crates (cursory look) The /src &amp;amp; /lib standard directories is a nice component Using .env to reference the database URL Requires some additional components for PSQL &amp;amp; Diesel</description></item><item><title>packer-bake-with-aws-native</title><link>/2021/05/jrbeverly-packer-bake-with-aws-native/</link><pubDate>Sat, 01 May 2021 01:10:12 +0000</pubDate><guid>/2021/05/jrbeverly-packer-bake-with-aws-native/</guid><description>Packer Bakery with AWS Native Creating pre-baked AMIs using Packer within AWS Native resources (Codepipeline / CodeBuild).
Notes Tuning minimum permissions can be a bit difficult with the CodePipeline/CodeBuild error messages Artifacts bucket should store only temporary/cache files, and should be destroyable Logs from CodePipeline &amp;amp; CodeBuild can be restricted to a specific log group Unique &amp;lsquo;key&amp;rsquo; identifier allow single-use of module within a common key-scope Events on-complete require additional resources/overhead Image is amazon pre-built, installing Packer on-the-fly Although nice to leverage IAM solely for this, the benefits don&amp;rsquo;t really outway the issues with leveraging CodePipeline for this kind of build.</description></item><item><title>bazel-and-aws-cdk</title><link>/2021/04/jrbeverly-bazel-and-aws-cdk/</link><pubDate>Tue, 27 Apr 2021 23:00:39 +0000</pubDate><guid>/2021/04/jrbeverly-bazel-and-aws-cdk/</guid><description>bazel-and-aws-cdk Prototyping ideas with using Bazel and AWS Cloud Development Kit to create cloudformation templates</description></item><item><title>repository-template-file-invoke-prototype</title><link>/2021/03/jrbeverly-repository-template-file-invoke-prototype/</link><pubDate>Thu, 25 Mar 2021 21:47:15 +0000</pubDate><guid>/2021/03/jrbeverly-repository-template-file-invoke-prototype/</guid><description>Repository Templating &amp;amp; File Automation Experimenting with a model of building a lightweight cron+bash system for performing templating&amp;amp;file modification to multiple repositories.
Idea The basics of this repository was the idea of leveraging the GitHub CLI (gh) to automate the creation of pull requests that were intended to facilitate common chore work in repositories. This would reduce the need to handle things like setting up license files, formatting, metadata, GitHub Actions, etc.</description></item><item><title>dotfiles</title><link>/2021/03/jrbeverly-dotfiles/</link><pubDate>Sun, 21 Mar 2021 02:26:13 +0000</pubDate><guid>/2021/03/jrbeverly-dotfiles/</guid><description>dotfiles A set of vim, zsh, git, and configuration files.</description></item><item><title>ml-learning-lab</title><link>/2021/03/jrbeverly-ml-learning-lab/</link><pubDate>Tue, 16 Mar 2021 02:03:08 +0000</pubDate><guid>/2021/03/jrbeverly-ml-learning-lab/</guid><description>Machine Learning Lab A repository for aggregating my machine learning exercises, practices and learning labs. The projects included in this repository are based on the coursework for Udacity&amp;rsquo;s Deep Learning Nanodegree Foundations. These are primarily from working on the Machine Learning Nanodegree offered by Udacity.
The project files are built using Jupyter Book into a web-accessible form.
Getting Started The conda environment for working with all of the Jupyter Notebooks is provided as environment.</description></item><item><title>codespace</title><link>/2021/03/jrbeverly-codespace/</link><pubDate>Mon, 08 Mar 2021 01:03:04 +0000</pubDate><guid>/2021/03/jrbeverly-codespace/</guid><description>Codespace Prebuilt, development environment in the browser – powered by VS Code.
This image acts as a catch-all image for doing full-stack development in a polyglot type environment. The running container makes use of the host docker service to allow for docker builds.</description></item><item><title>home</title><link>/2020/11/jrbeverly-home/</link><pubDate>Sat, 28 Nov 2020 02:46:39 +0000</pubDate><guid>/2020/11/jrbeverly-home/</guid><description>HomeLab - Internal Tooling Ansible playbooks for configuring services running within my internal home cloud.
Getting Started DevContainers The DevContainer environment can be started by opening the repository in VSCode and installing the &amp;lsquo;Remote - Containers&amp;rsquo; extension. When started, the prompt will build and image and configure the container.
The deployments to any of the environment can be triggered by running any of the helper scripts available in /opt/bin. To deploy the codelab environment, you can run codelab.</description></item><item><title>aws-lightsail-codespaces</title><link>/2020/08/jrbeverly-aws-lightsail-codespaces/</link><pubDate>Thu, 20 Aug 2020 22:21:48 +0000</pubDate><guid>/2020/08/jrbeverly-aws-lightsail-codespaces/</guid><description>Running code-server on AWS Lightsail Summary Run VS Code on an AWS Lightsail instance with auto-generated password and static IP. Early experiments with cloud-driven development environments configured on-demand using terraform.
Initial exploratory work for seeing what changes exist in the workflows, and any issues that may arise as a result of working in Lightsail.
Notes Below are some quick points noted while experimenting with this:
AWS Access Keys In comparison to running this on ECS or EC2, AWS access keys need to be generated and supplied if you wish to run AWS commands.</description></item><item><title>aws-lambda-simple-service</title><link>/2020/08/jrbeverly-aws-lambda-simple-service/</link><pubDate>Wed, 19 Aug 2020 23:16:36 +0000</pubDate><guid>/2020/08/jrbeverly-aws-lambda-simple-service/</guid><description>Express in Deployments A simple Express application built with the intent to test an Express server running in different environments (local, docker, lambda).
Usage The available make commands can be listed with make help:
Usage: make &amp;lt;target&amp;gt; help This help text. Serverless deploy Deploy the lambda with serverless remove Destroys the instructure Express local Locally run the app Docker docker Build and run in a docker container Notes Simple service with the intent to be used for some AWS work involving cloud costing, cold starts and on-demand provisioning of services.</description></item><item><title>jrbeverly.web</title><link>/2020/06/jrbeverly-jrbeverly.web/</link><pubDate>Sat, 27 Jun 2020 21:01:56 +0000</pubDate><guid>/2020/06/jrbeverly-jrbeverly.web/</guid><description>jrbeverly Represents the infrastructure resources of &amp;lsquo;jrbeverly&amp;rsquo;, keeping track of infrastructure components, assets and other resources that are needed for components.
Directory Mappings The directory layout is modelled after the Linux directories (/var, /etc/, /root, /srv, /opt, etc). This is intended to handle cases as they are adopted into the standards.
/srv Represents the website resources for any hosted domain.</description></item><item><title>boston-housing</title><link>/2020/02/jrbeverly-boston-housing/</link><pubDate>Mon, 24 Feb 2020 17:50:55 +0000</pubDate><guid>/2020/02/jrbeverly-boston-housing/</guid><description>Predicting Boston Housing Prices Evaluate the performance and predictive power of a model that has been trained and tested on data collected from homes in suburbs of Boston, Massachusetts. A model trained on this data that is seen as a good fit could then be used to make certain predictions about a home — in particular, its monetary value. This model would prove to be invaluable for someone like a real estate agent who could make use of such information on a daily basis.</description></item><item><title>charityml</title><link>/2020/02/jrbeverly-charityml/</link><pubDate>Mon, 24 Feb 2020 17:50:35 +0000</pubDate><guid>/2020/02/jrbeverly-charityml/</guid><description>Finding Donors for CharityML Employ several supervised algorithms to accurately model individuals' income using data collected from the 1994 U.S. Census. From the best candidate algorithm from preliminary results and further optimize this algorithm to best model the data. Construct a model that accurately predicts whether an individual makes more than $50,000. This sort of task can arise in a non-profit setting, where organizations survive on donations. Understanding an individual&amp;rsquo;s income can help a non-profit better understand how large of a donation to request, or whether or not they should reach out to begin with.</description></item><item><title>customer-segments</title><link>/2020/02/jrbeverly-customer-segments/</link><pubDate>Mon, 24 Feb 2020 17:48:47 +0000</pubDate><guid>/2020/02/jrbeverly-customer-segments/</guid><description>Creating Customer Segments Analyze a dataset containing data on various customers' annual spending amounts (reported in monetary units) of diverse product categories for internal structure. One goal of this project is to best describe the variation in the different types of customers that a wholesale distributor interacts with. Doing so would equip the distributor with insight into how to best structure their delivery service to meet the needs of each customer.</description></item><item><title>dog-project</title><link>/2020/01/jrbeverly-dog-project/</link><pubDate>Sat, 11 Jan 2020 18:05:28 +0000</pubDate><guid>/2020/01/jrbeverly-dog-project/</guid><description>Classification of Dogs My implementation of the Convolutional Neural Networks (CNN) algorithm for identifying a canine’s breed from an image. Additionally, it supply the resembled dog breed if provided an image of a human.
Classification You can see an example classification for the German Shepherd picture below:
And an example of a misclassification for a rotweiler.
Notes You can see my full analysis of the classifier in the notebook, but a snippet is included below</description></item><item><title>quadcopter</title><link>/2020/01/jrbeverly-quadcopter/</link><pubDate>Fri, 10 Jan 2020 02:31:05 +0000</pubDate><guid>/2020/01/jrbeverly-quadcopter/</guid><description>Quadcopter using Reinforcement Learning My implementation of the DDPG reinforcement learning algorithm to solve the problem of a quadcopter taking flight.
I have included a reference to the DDPG paper used in the development of the flying agent:
Continuous control with deep reinforcement learning Timothy P. Lillicrap, Jonathan J. Hunt, Alexander Pritzel, Nicolas Heess, Tom Erez, Yuval Tassa, David Silver, Daan Wierstra
We adapt the ideas underlying the success of Deep Q-Learning to the continuous action domain.</description></item><item><title>bmx</title><link>/2020/01/jrbeverly-bmx/</link><pubDate>Wed, 08 Jan 2020 18:15:28 +0000</pubDate><guid>/2020/01/jrbeverly-bmx/</guid><description>BMX BMX grants you API access to your AWS accounts, based on Okta credentials that you already own.
It uses your Okta identity to create short-term AWS STS tokens, as an alternative to long-term IAM access keys. BMX manages your STS tokens with the following commands:
bmx print writes your short-term tokens to stdout as AWS environment variables. You can execute bmx print&amp;rsquo;s output to make the environment variables available to your shell.</description></item><item><title>git-timeline</title><link>/2020/01/jrbeverly-git-timeline/</link><pubDate>Sat, 04 Jan 2020 01:26:48 +0000</pubDate><guid>/2020/01/jrbeverly-git-timeline/</guid><description>Git Timeline Allows bulk modification of the commit dates of a repository, changing the history of a repository.
Usage # Creates the demo repository ./git-timeline.bash clone # Copies the demo repository to the working environment ./git-timeline.bash working # Exports the history of the git repository to files ./git-timeline.bash history You can then edit the dates of the three files emitted:
FIRST - The first commit to the repository HISTORY - The commit history LATEST - The most recent commit to the repository After you have done this, you can then run apply and show:</description></item><item><title>aws-lambda-remote-session</title><link>/2020/01/jrbeverly-aws-lambda-remote-session/</link><pubDate>Fri, 03 Jan 2020 22:26:00 +0000</pubDate><guid>/2020/01/jrbeverly-aws-lambda-remote-session/</guid><description>AWS Lambda PowerShell Example A simple Lambda function written in PowerShell to validate if New-PSSession can be leveraged from an AWS Lambda.
The objective of this repository was to determine if it was possible to use New-PSSession from an AWS Lambda. This would allow for modification of services like Office365 using remote sessions from AWS without requiring an ECS/EC2 container. Without a custom lambda runtime (or some way of enabling WSMan), it would be difficult to do this with a vanilla lambda execution environment.</description></item><item><title>aws-chat-app</title><link>/2019/12/jrbeverly-aws-chat-app/</link><pubDate>Mon, 30 Dec 2019 23:57:22 +0000</pubDate><guid>/2019/12/jrbeverly-aws-chat-app/</guid><description>AWS Chat App SAM Application for a simple chat application based on API Gateways new WebSocket API feature. This was originally developed as an experiment to see how viable running a chat-bot in a fully serverless environment, as opposed to just running on a container in ECS.
This repository is based on Announcing WebSocket APIs in Amazon API Gateway, with the cloudformation and lambdas from simple-websockets-chat-app.
Usage A build-harness created with make is available for the repository.</description></item><item><title>hubot-in-aws</title><link>/2019/12/jrbeverly-hubot-in-aws/</link><pubDate>Sat, 28 Dec 2019 15:56:31 +0000</pubDate><guid>/2019/12/jrbeverly-hubot-in-aws/</guid><description>Hubot in AWS ECS Hubot deployment in AWS using AWS ECS Fargate. This was prototyped out while I was evaluating ChatOps strategies that could be used to wrap existing web interfaces or require minimal overhead.
Usage A build-harness created with make is available for the repository. This harness simplifies the commands necessary to build and deploy the project. You can see the available targets by running make help:
Usage: make &amp;lt;target&amp;gt; help This help text.</description></item><item><title>pwsh-from-github</title><link>/2019/11/jrbeverly-pwsh-from-github/</link><pubDate>Sun, 17 Nov 2019 15:13:06 +0000</pubDate><guid>/2019/11/jrbeverly-pwsh-from-github/</guid><description>Powershell Library on GitHub Summary A powershell library that is installed from GitHub, rather than from Powershellgallery.
Usage Downloading from GitHub:
# Enable installing from github Install-Module -Name InstallModuleFromGitHub # Install the module Install-ModuleFromGitHub -GitHubRepo jrbeverly/pwsh-from-github # Perform Actions Write-Hello -Name &amp;#34;World&amp;#34; Write-World -Message &amp;#34;LFG&amp;#34; Notes Experimenting with using InstallModuleFromGitHub, instead of using Powershell gallery.
I have noticed that this requires all of the scripts be at the root of the repository, rather than using a folder structure like so:</description></item><item><title>proposals-concept</title><link>/2019/10/jrbeverly-proposals-concept/</link><pubDate>Wed, 30 Oct 2019 03:40:50 +0000</pubDate><guid>/2019/10/jrbeverly-proposals-concept/</guid><description>Proposals Experimenting with the underlying infrastructure for a GitHub based proposals mechanisms that deploys to a web resource (website/subpage/etc)
Motivations Automation to ensure contribution guidelines are both accessible and followed (e.g. first contribution bot, linting) Contribution previews, either by links to markdown rendering or branch previews Support for supplemental resources (e.g. assets/list-of-items.csv) Methods to organize the proposals better (date? slugs? IDs?) Simple layout in code (minimal overhead), with tooling to move assets into the correct locations When working with code, the proposals have some organization mechanism Minimal barriers when trying to write a proposal Notes Using date-based directory organization helps for filtering based on the latest proposals.</description></item><item><title>exp-circleci-orbs</title><link>/2019/10/jrbeverly-exp-circleci-orbs/</link><pubDate>Wed, 30 Oct 2019 02:21:11 +0000</pubDate><guid>/2019/10/jrbeverly-exp-circleci-orbs/</guid><description>Experimenting with CircleCI Orbs Experimenting with CircleCI Orbs for reducing code re-use in templates
Usages cp Deploy to S3
orbs: awscli: jrbeverly/awscli@0.0.5 version: 2.1 workflows: Deploy to S3: jobs: - awscli/aws-copy-to: bucket: hello-bucket namespace: some/terraform source: some/path sync Deploy to S3
orbs: awscli: jrbeverly/awscli@0.0.5 version: 2.1 workflows: Deploy to S3: jobs: - awscli/aws-sync-to: bucket: hello-bucket namespace: some/terraform</description></item><item><title>bazel-csharp-testcases</title><link>/2019/10/jrbeverly-bazel-csharp-testcases/</link><pubDate>Sat, 26 Oct 2019 21:27:51 +0000</pubDate><guid>/2019/10/jrbeverly-bazel-csharp-testcases/</guid><description>Bazel CSharp Rules Examples Overview This repository provides a set of usages for the bazel csharp rules. The idea behind these examples is to cover edge cases that are encountered during development, and provide a comprehensive test (&amp;amp; prototype) suite.
While working on the bazel csharp rules, I have encountered bugs or small quirks that I would like to encode records of. Some of these are very minor details, so I felt it would work best to have them as an external repository.</description></item><item><title>viewdocs-autodoc</title><link>/2019/10/jrbeverly-viewdocs-autodoc/</link><pubDate>Sat, 05 Oct 2019 20:47:31 +0000</pubDate><guid>/2019/10/jrbeverly-viewdocs-autodoc/</guid><description>Viewdocs Autodoc This was an early concept I was working with for converting metadata files (json/yml) into standard README markdown files using simple bash and templates. Ultimately I did not go in this direction, as I found that I was not making the best use of the customization yielded from using with bash + templates. A simple templating engine provided all the basics that I was ultimately after.
Below I have described some of the template concepts I was exploring at the time:</description></item><item><title>awesome-terraform-prototype</title><link>/2019/10/jrbeverly-awesome-terraform-prototype/</link><pubDate>Sat, 05 Oct 2019 20:41:57 +0000</pubDate><guid>/2019/10/jrbeverly-awesome-terraform-prototype/</guid><description>Awesome Terraform Prototype An experiment using mkdocs and a series of json/yml files to define an awesome list.
The markdown files are automatically generated from the yml files that define each element of the list (tags/metadata/etc). These files are then piped into mkdocs, which yields a material theme website for the project.</description></item><item><title>exp-svg-icon-processing</title><link>/2019/10/jrbeverly-exp-svg-icon-processing/</link><pubDate>Sat, 05 Oct 2019 20:37:56 +0000</pubDate><guid>/2019/10/jrbeverly-exp-svg-icon-processing/</guid><description>SVG Icon Processing Summary Experiment with programmatically generating color variants for SVG files using a JSON definition file with the source SVG.
Usage The variants of each of the files is defined as a dictionary (string:object). The key for the dictionary matches the name of the variant. The object defines a collection of id and properties. These will be merged into the SVG to generate the variant icon. An example definition file is included below.</description></item><item><title>bullseye-exp</title><link>/2019/10/jrbeverly-bullseye-exp/</link><pubDate>Sat, 05 Oct 2019 20:35:47 +0000</pubDate><guid>/2019/10/jrbeverly-bullseye-exp/</guid><description>BullsEye Experimentation Summary Experiment with BullsEye for building command-driven tooling (build-systems).
Usage Experimenting with using BullsEye in a dotnet project. BullsEye doesn&amp;rsquo;t handle parsing of command line arguments, instead recommends using a tool for parsing them.
var app = new CommandLineApplication(throwOnUnexpectedArg: false); var foo = app.Option&amp;lt;string&amp;gt;(&amp;#34;--foo&amp;#34;, &amp;#34;foo&amp;#34;, CommandOptionType.SingleValue); BullsEye can then be used to built a higher level build system for languages (terraform, docker, etc).
Notes Creates common build-systems for templates (terraform-module, docker image) Auto-generate the console apps (BullsEye, CommandLineApplication) from a definition Define the system, then generate interfaces (service, cli, client, etc)</description></item><item><title>lab-starter</title><link>/2019/09/jrbeverly-lab-starter/</link><pubDate>Sun, 01 Sep 2019 20:31:22 +0000</pubDate><guid>/2019/09/jrbeverly-lab-starter/</guid><description>GitHub Learning Lab - Lab Starter Noticed this when working with GitHub Actions that you can have a automated &amp;lsquo;teacher&amp;rsquo; by using linting + GitHub Bot. Thought this was an interesting idea, and have started this repository to get a better understanding of how this actually works.
With GitHub now having its own CI/CD Pipeline, it may be possible to create all sorts of tutorials for setting up applications. The first one that comes to mind is gamedev with something like Godot.</description></item><item><title>hello-github-actions</title><link>/2019/09/jrbeverly-hello-github-actions/</link><pubDate>Sun, 01 Sep 2019 19:56:26 +0000</pubDate><guid>/2019/09/jrbeverly-hello-github-actions/</guid><description>Welcome to &amp;ldquo;Hello World&amp;rdquo; with GitHub Actions This course will walk you through writing your first action and using it with a workflow file.
Ready to get started? Navigate to the first issue.</description></item><item><title>dotnet-native-corert</title><link>/2019/02/jrbeverly-dotnet-native-corert/</link><pubDate>Sun, 03 Feb 2019 03:52:04 +0000</pubDate><guid>/2019/02/jrbeverly-dotnet-native-corert/</guid><description>.NET Core Native Compilation Experiments A simple CI/CD pipeline making use of CoreRT to build linux and windows copies of a &amp;ldquo;Hello World&amp;rdquo; console application.
Notes CoreRT currently does not support compilation cross-compilation (as it is not supported yet). AOT for a linux binary requires non-dotnet dependencies (that need to be installed to be base image) At present it is likely best to use Windows docker images for building the dotnet native jobs.</description></item><item><title>make-exp</title><link>/2018/12/jrbeverly-make-exp/</link><pubDate>Wed, 12 Dec 2018 22:46:15 +0000</pubDate><guid>/2018/12/jrbeverly-make-exp/</guid><description>Makefile Experiments Summary Experimenting with using makefiles as a build harness type structure. The idea is to package makefile using GitHub, that can then be downloaded when running.
Conceptual Usage As the structure is simply an experiment, no targets are actually implemented. At the top of the Makefile, you can include the makefile using the following:
-include $(shell curl -sSL -o .build-system &amp;#34;https://.../makefile&amp;#34;; echo .build-system) This will download a Makefile called .</description></item><item><title>infrastructure-labs</title><link>/2018/11/jrbeverly-infrastructure-labs/</link><pubDate>Fri, 02 Nov 2018 23:41:32 +0000</pubDate><guid>/2018/11/jrbeverly-infrastructure-labs/</guid><description>Infrastructure Summary The specification of jrbeverlylabs as a set of terraform modules.
Usage To run this you need to execute:
terraform init terraform plan terraform apply Notes This was a simple experiment making use of the gitlab provider of terraform. The idea was to see if it would assist in the process of maintaining jrbeverlylabs between gitlab.com and my internal gitlab instance.</description></item><item><title>xunit-metadata</title><link>/2018/11/jrbeverly-xunit-metadata/</link><pubDate>Fri, 02 Nov 2018 00:52:39 +0000</pubDate><guid>/2018/11/jrbeverly-xunit-metadata/</guid><description>XUnit.Metadata Summary Strongly-typed attributes for the management and organization of tests. As opposed to using strings throughout the code, [Trait(&amp;quot;Category&amp;quot;, &amp;quot;Unit&amp;quot;)], you can use strongly-typed attributes for organizing tests.
Getting Started With xUnit v2 you can markup tests with traits, particullary of interest is the category key. Using traits you can sort tests or control execution of tests from the command line. You can install in your project using the Nuget Manager Console:</description></item><item><title>wifi-web</title><link>/2018/11/jrbeverly-wifi-web/</link><pubDate>Fri, 02 Nov 2018 00:52:35 +0000</pubDate><guid>/2018/11/jrbeverly-wifi-web/</guid><description>Wifi Web Summary Wifi Web provides an autorun USB for connecting to wireless access points for devices that do not have access to a camera. It opens an HTML page that provides easy access to the Wifi connection details.
If you have a camera-enabled device, you can scan Wifi connection details using a QR Code (or any barcode type).
Installation You can install Wifi Web onto a USB stick by unzipping the most recent build.</description></item><item><title>stack-opengl</title><link>/2018/11/jrbeverly-stack-opengl/</link><pubDate>Fri, 02 Nov 2018 00:52:30 +0000</pubDate><guid>/2018/11/jrbeverly-stack-opengl/</guid><description>stack-opengl Summary stack-opengl is a variant of stack-net written in OpenGL. It uses extremely simple shaders and OpenGL programming to create a block stacking application.
Getting Started The project uses premake4 as the cross-platform build system. You will need to build the external dependencies of the project, by running a root level build. You can then build the project itself. You can do so as such:
premake4 gmake make cd src/ premake4 gmake make .</description></item><item><title>stack-net</title><link>/2018/11/jrbeverly-stack-net/</link><pubDate>Fri, 02 Nov 2018 00:52:29 +0000</pubDate><guid>/2018/11/jrbeverly-stack-net/</guid><description>Stack-NET Summary A block blueprinter, built using a visual graph style approach to graphics.
Getting Started The project is based on the old approach to C# projects. The project should be opened in Visual Studio, built, then run.
Acknowledgements The project icon is retrieved from the Noun Project. The original source material has been altered for the purposes of the project. The icon is used under the terms of the Public Domain.</description></item><item><title>raytracer</title><link>/2018/11/jrbeverly-raytracer/</link><pubDate>Fri, 02 Nov 2018 00:52:27 +0000</pubDate><guid>/2018/11/jrbeverly-raytracer/</guid><description>RayTracer Summary A Raytracer that receives a scene defined in lua, and produces an image output.
Getting Started Compilation follows the standard process defined by the UWaterloo CS488 sample projects.
We use premake4 as our cross-platform build system. First you will need to build all the static libraries that the projects depend on. To build the libraries, open up a terminal, and cd to the top level of the CS488 project directory and then run the following:</description></item><item><title>profile</title><link>/2018/11/jrbeverly-profile/</link><pubDate>Fri, 02 Nov 2018 00:52:26 +0000</pubDate><guid>/2018/11/jrbeverly-profile/</guid><description>jrbeverly.profile Summary This is a one page user profile for Jonathan Beverly (jrbeverly - i.e. me), linking to multiple online identities, relevant external sites, and popular social networking websites. Not all of them are included, but most of the relevant ones are.
Build Process The process of minimizing the web resources is handled using the command line utility of Minify which is available here. The process is used manually as opposed to leveraging a specific build system, is to experiment with more granular controls for website compilation.</description></item><item><title>exp-portfolio</title><link>/2018/11/jrbeverly-exp-portfolio/</link><pubDate>Fri, 02 Nov 2018 00:52:25 +0000</pubDate><guid>/2018/11/jrbeverly-exp-portfolio/</guid><description>jrbeverly portfolio Summary Collections data from a specified list of gitlab projects, then converts them into static HTML briefs.
Getting Started The project is designed to git clone a series of repository, then collect information from each of them. This includes the project icon, name, license, path, etc.
From this information, the project will then for each repository create:
A brief - A simple static page featuring the README.md of the project rendered in a viewdocs format A redirect link, allowing one to navigate to jrbeverly.</description></item><item><title>office-depot</title><link>/2018/11/jrbeverly-office-depot/</link><pubDate>Fri, 02 Nov 2018 00:52:22 +0000</pubDate><guid>/2018/11/jrbeverly-office-depot/</guid><description>office-depot Summary office-depot is a container based software development stack.
Getting Started Getting started is as simple as using docker-compose. You can do so as such:
docker-compose up --env-file=office-depot.env -d Updating and Upgrading If you wish to upgrade the container stack, you need to run the following commands:
docker-compose stop docker-compose rm -v docker-compose pull You can then start the docker environment.
docker-compose up --env-file=office-depot.env -d Cleaning After upgrading, you can be left with unused images or containers.</description></item><item><title>mirroring</title><link>/2018/11/jrbeverly-mirroring/</link><pubDate>Fri, 02 Nov 2018 00:52:21 +0000</pubDate><guid>/2018/11/jrbeverly-mirroring/</guid><description>Mirroring Summary A lightweight bash script that allows easy mirroring of projects to external git hosts.
Getting started Simply fork this repository, as it has all the scripts necessary for performing mirrors. You can then add your repositories into the assets/ directory. You will want to store them as such:
&amp;gt; repoA/
&amp;gt; bitbucket.config
&amp;gt; github.config
&amp;gt; gitlab.config
&amp;gt; someService.config
&amp;gt; REPO
&amp;gt; repoB/
&amp;gt; ...
&amp;gt; repoC/
&amp;gt; ...
Each repositroy is its own directory.</description></item><item><title>localization-net</title><link>/2018/11/jrbeverly-localization-net/</link><pubDate>Fri, 02 Nov 2018 00:52:18 +0000</pubDate><guid>/2018/11/jrbeverly-localization-net/</guid><description>Localization.NET Concept Summary A simple experiment prototyping a concept for strongly typed language terms.
Note: The generated component is not built with this. This is a usage prototype only (no generator is included).
Getting Started The idea that Localization.NET is attempting to conceptualize is one where an interface is used as the primary mechanism for declaring language terms. Attributes can be used to include more contextual information (usage, type, namespace). The Roslyn compiler can then use this information to generate the underlying code to facilitate the Language terms.</description></item><item><title>issues-style</title><link>/2018/11/jrbeverly-issues-style/</link><pubDate>Fri, 02 Nov 2018 00:52:13 +0000</pubDate><guid>/2018/11/jrbeverly-issues-style/</guid><description>Issues.Style Summary A style guide for issue management, release versioning, Git Flow and repository documentation.
Description In order to speed up the initialization process of a new gitlab project, Issues.Style provides a set of common labels and issues that might be used when setting up a new project. The project provides methods for quickly setting up the project, specifically providing the following:
Labels - Grouped by color, according to broad themes Setup Issues - Initialization labels, including licensing, documentation, CI and metadata.</description></item><item><title>project-icons</title><link>/2018/11/jrbeverly-project-icons/</link><pubDate>Fri, 02 Nov 2018 00:52:12 +0000</pubDate><guid>/2018/11/jrbeverly-project-icons/</guid><description>jrbeverly.icons Summary A collection of scalable vector graphics (SVG) that define project and group icons.
Build You can build the icons using the tool rsvg-convert. To build with rsvg-convert, you can do the following:
rsvg-convert -f svg icon.svg &amp;gt; output.svg rsvg-convert -f png icon.svg &amp;gt; output.png It is recommend to use the build scripts available in build/ or in the local source directory. These scripts are used in the build pipeline, ensuring that all arguments and attributes are set for compilation of the icons.</description></item><item><title>gitlab-ci-yml</title><link>/2018/11/jrbeverly-gitlab-ci-yml/</link><pubDate>Fri, 02 Nov 2018 00:52:10 +0000</pubDate><guid>/2018/11/jrbeverly-gitlab-ci-yml/</guid><description>gitlab-ci.yml A collection of GitLab CI configuration files that are used by my projects. Stored here as the process of docker projects are polished and standardized.
Getting Started Each of the dockerfiles is presented with a simple .gitlab-ci.yml file that uses one of my docker images. The resources referenced by the definition are not included in this project. You can start by copying the .gitlab-cy.yml, then replacing the relevant bits.</description></item><item><title>entity-net</title><link>/2018/11/jrbeverly-entity-net/</link><pubDate>Fri, 02 Nov 2018 00:52:07 +0000</pubDate><guid>/2018/11/jrbeverly-entity-net/</guid><description>Entity.NET Concept Summary A simple experiment prototyping a concept for strongly typed ORMs.
Getting Started The idea that Entity.NET is attempting to conceptualize is one where strongly-typed objects are used with an ORM system. The primary objective is to use strongly typed identifiers (Keys.Customer) that restricts the usages of an applications ORM. The concept is from the following scenario:
var cust = new Models.Customer() { Name = &amp;#34;John Doe&amp;#34; }; var entity = Repository.</description></item><item><title>distributedrpc</title><link>/2018/11/jrbeverly-distributedrpc/</link><pubDate>Fri, 02 Nov 2018 00:41:09 +0000</pubDate><guid>/2018/11/jrbeverly-distributedrpc/</guid><description>DistributedRPC Summary A multi-client, multi-server environment that relies on a binder to facilitate an RPC system.
Getting Started To make (&amp;ldquo;compile and link&amp;rdquo;) all components of the project, you can quickly get started with
make exec Or if you are doing quick debugging
make exec &amp;amp;&amp;amp; ./binder You can also invidiaully build each component with make &amp;lt;component&amp;gt;.
Notes The project is over-commented to explain each line of code. This is for the purposes of explaining how the overall project connects together.</description></item><item><title>contentbundler</title><link>/2018/11/jrbeverly-contentbundler/</link><pubDate>Fri, 02 Nov 2018 00:41:04 +0000</pubDate><guid>/2018/11/jrbeverly-contentbundler/</guid><description>ContentBundler Summary A proof of concept for generation of strongly typed paths using the Roslyn Framework.
Getting Started ContentBundler is provided as an command line application, originally adapted from an XNA Content Compiler. The new version greatly simplifies the code requirements, leveraging Roslyn for the code generation. An example is available from test/assets, which will generate the result [PatchQ.cs]
./ContentBundler.exe --archive patch-Q.zip --file PatchQ.cs --class PatchQ --namespace PlatformerGame.Assets This will then output a series of static classes.</description></item><item><title>udacicards</title><link>/2018/04/jrbeverly-udacicards/</link><pubDate>Sat, 07 Apr 2018 20:55:53 +0000</pubDate><guid>/2018/04/jrbeverly-udacicards/</guid><description>UdaciCards Summary For the UdaciCards project, you will build a mobile application (Android or iOS - or both) that allows users to study collections of flashcards. The app will allow users to create different categories of flashcards called &amp;ldquo;decks&amp;rdquo;, add flashcards to those decks, then take quizzes on those decks.
Installation You can install the project dependencies using:
cd src/udacicards/ yarn The you can start the application:
yarn start To troubleshoot the issues of the application, you can review React Native - Getting Started.</description></item><item><title>jollybot</title><link>/2018/04/jrbeverly-jollybot/</link><pubDate>Sat, 07 Apr 2018 20:50:44 +0000</pubDate><guid>/2018/04/jrbeverly-jollybot/</guid><description>JollyBot Summary Prisoners' Dilemma A.I. bot performing an &amp;lsquo;Olive Branch&amp;rsquo; strategy focusing on attempting to cooperate whenever possible. The bot attempts to establish cooperation, even in cases where the opposing agent may appear hostile (e.g. always defect).
Description The iterated prisoner’s dilemma is a classic two-person game which consists of a number of rounds. In each round, each person can either defect by taking $1 from a (common) pile, or cooperate by giving $2 from the same pile to the other person.</description></item><item><title>readable</title><link>/2018/01/jrbeverly-readable/</link><pubDate>Wed, 17 Jan 2018 23:40:48 +0000</pubDate><guid>/2018/01/jrbeverly-readable/</guid><description>Readable Udacity Nanodegree React Project
Installing Server cd src/api npm install node start Installing Client cd src/client npm install npm start API Server Information about the API server and how to use it can be found in its README file.
Acknowledgements The project icon is retrieved from the Noun Project. The original source material has been altered for the purposes of the project. The icon is used under the terms of the Public Domain.</description></item><item><title>myreads</title><link>/2017/11/jrbeverly-myreads/</link><pubDate>Sat, 18 Nov 2017 22:49:02 +0000</pubDate><guid>/2017/11/jrbeverly-myreads/</guid><description>MyReads Project Summary A digital bookshelf app that allows you to select and categorize books you have read, are currently reading, or want to read.
Description MyReads is a digital bookshelf app that allows you to select and categorize books you have read, are currently reading, or want to read. It is built as a project for Udacity React Nanodegree.
Getting Started The backend API uses a fixed set of cached search results and is limited to a particular set of search terms, which can be found in SEARCH_TERMS.</description></item><item><title>githooks</title><link>/2017/09/jrbeverly-githooks/</link><pubDate>Sat, 16 Sep 2017 01:04:05 +0000</pubDate><guid>/2017/09/jrbeverly-githooks/</guid><description>Githooks Summary GitHooks provides a multi-hook framework for Git Hooks, along with a collection of scripts for the purposes of encouraging a commit policy, altering the project environment depending on the state of the repository, and implementing continuous integration workflows. The framework allows multi-script execution, you can use GitHooks to automate or optimize virtually any aspect of your development workflow.
Getting Started Git Hooks are event-based scripts you can place in a hooks directory to trigger actions at certain points in git’s execution.</description></item><item><title>homelab</title><link>/2017/05/jrbeverly-homelab/</link><pubDate>Wed, 31 May 2017 22:54:15 +0000</pubDate><guid>/2017/05/jrbeverly-homelab/</guid><description>Homelab Summary A collection of templates and utility scripts used in my homelab. Most of these are just snippets or experiments.
Getting Started As most of the scripts are self-contained, you can clone the repository:
git clone git://homelab/homelab And copy the relevant scripts into /usr/bin/ (or others) as necessary. You can also skip that, and just copy the contents of a file, then paste it into a fresh nano instance.</description></item><item><title>jotto</title><link>/2017/05/jrbeverly-jotto/</link><pubDate>Wed, 31 May 2017 14:21:28 +0000</pubDate><guid>/2017/05/jrbeverly-jotto/</guid><description>Jotto Summary Jotto is a logic-oriented word game played with two players. Each player picks a secret word of five letters (that is in the dictionary), and the object of the game is to correctly guess the other player&amp;rsquo;s word first. Players take turns guessing and giving the number of Jots, or the number of letters that are in both the guessed word and the secret word.
The Jotto application is built with a single player, playing against a computer.</description></item></channel></rss>